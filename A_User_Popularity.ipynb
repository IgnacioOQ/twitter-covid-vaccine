{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "\n",
    "import pprint\n",
    "import json\n",
    "import glob\n",
    "from random import random, randrange\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pandas\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the regular dictionary\n",
    "f = open('author_popularity_dictionary','rb')\n",
    "popularity_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "com_data = pd.read_csv(\"PT-pruned-louvain.gexf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to the popularity of those who were always active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [13,48,6,49,104,57,85,80]\n",
    "labels = [\"Democrats\",\"Republicans\",\"Unorthodox\",\"Public Health\",\"Anti-Vaxxers\",\"French\",\"Indian\",\"FreedomUK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_com_nodes(com):\n",
    "    com_nodes = []\n",
    "    subset = com_data[com_data['modularity_class']==com]\n",
    "    for i in subset['Id']:\n",
    "        com_nodes.append(i)\n",
    "    return com_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_com(node):\n",
    "    com = com_data[com_data['Id']==node]['modularity_class']\n",
    "    val = com.values[0]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_node_com('johnjosephTX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_auth_time(author,pre=True):\n",
    "    date_break = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "    data = popularity_dict[author]\n",
    "    value = False\n",
    "    for entry in data:\n",
    "        date = datetime.datetime.strptime(entry[0],'%y-%m-%d-%H:%M:%S')\n",
    "        if pre:\n",
    "            if date <= date_break:\n",
    "                value=True\n",
    "        else:\n",
    "            if date_break <= date:\n",
    "                value=True\n",
    "    return value\n",
    "\n",
    "def check_auth_continuity(author):\n",
    "    date_break = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "    data = popularity_dict[author]\n",
    "    pre = False\n",
    "    post = False\n",
    "    for entry in data:\n",
    "        date = datetime.datetime.strptime(entry[0],'%y-%m-%d-%H:%M:%S')\n",
    "        if date <= date_break:\n",
    "            pre=True\n",
    "        if date_break <= date:\n",
    "            post=True\n",
    "    if (pre & post):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_followers(com,pre=True):\n",
    "    date_break = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "    com_nodes = get_com_nodes(com)\n",
    "    # Consider only those who were active before and after  \n",
    "    com_auth = []\n",
    "    for node in com_nodes:\n",
    "        if check_auth_continuity(node):\n",
    "            com_auth.append(node)   \n",
    "    com_norm = len(com_auth)\n",
    "    com_count = float(0)\n",
    "    for author in com_auth: # only those active before and after\n",
    "        data = popularity_dict[author]\n",
    "        auth_norm = len(data)\n",
    "        auth_count = float(0)\n",
    "        for entry in data:\n",
    "            date = datetime.datetime.strptime(entry[0],'%y-%m-%d-%H:%M:%S')\n",
    "            if pre:\n",
    "                if date <= date_break:\n",
    "                    auth_count += entry[1] # count followers\n",
    "                    auth_count += entry[2] # count friends\n",
    "            else:\n",
    "                if date_break <= date:\n",
    "                    auth_count += entry[1] # count followers\n",
    "                    auth_count += entry[2] # count friends                    \n",
    "        auth_mean = auth_count/auth_norm\n",
    "        com_count += auth_mean\n",
    "    com_mean = com_count/com_norm\n",
    "    return com_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = False\n",
    "\n",
    "if recompute:\n",
    "    results = pd.DataFrame(columns=['Community_Name','Community_Id','Prior_Active_Users','Posterior_Active_Users',\\\n",
    "                                    'Continuous_Active_Users','Prior_Mean','Posterior_Mean'])\n",
    "    for i in tqdm(range(len(clusters))):\n",
    "        data = []\n",
    "        data.append(labels[i])\n",
    "        data.append(clusters[i])\n",
    "        com_nodes = get_com_nodes(clusters[i])\n",
    "        prior_count = 0\n",
    "        posterior_count = 0\n",
    "        continuity_count = 0\n",
    "        for node in com_nodes:\n",
    "            if check_auth_time(node,pre=True):\n",
    "                prior_count += 1\n",
    "            if check_auth_time(node,pre=False):\n",
    "                posterior_count += 1\n",
    "            if check_auth_continuity(node):\n",
    "                continuity_count += 1\n",
    "        data.append(prior_count)\n",
    "        data.append(posterior_count)\n",
    "        data.append(continuity_count)\n",
    "        prior_mean = get_mean_followers(clusters[i],pre=True)\n",
    "        data.append(prior_mean)\n",
    "        posterior_mean = get_mean_followers(clusters[i],pre=False)\n",
    "        data.append(posterior_mean)\n",
    "        results.loc[len(results)] = data\n",
    "    results.to_csv('prepost_followers.csv', index=False)\n",
    "    results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('prepost_followers.csv')\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "data\n",
    "#data.to_csv('prepost_followers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Community_Name</th>\n",
       "      <th>Community_Id</th>\n",
       "      <th>Prior_Active_Users</th>\n",
       "      <th>Posterior_Active_Users</th>\n",
       "      <th>Continuous_Active_Users</th>\n",
       "      <th>Prior_Mean</th>\n",
       "      <th>Posterior_Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dems</td>\n",
       "      <td>13</td>\n",
       "      <td>51319</td>\n",
       "      <td>87173</td>\n",
       "      <td>46700</td>\n",
       "      <td>8118.406542</td>\n",
       "      <td>25295.379267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reps</td>\n",
       "      <td>48</td>\n",
       "      <td>33878</td>\n",
       "      <td>68566</td>\n",
       "      <td>32197</td>\n",
       "      <td>3321.962841</td>\n",
       "      <td>15161.272587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disenfranch</td>\n",
       "      <td>6</td>\n",
       "      <td>22596</td>\n",
       "      <td>57201</td>\n",
       "      <td>19770</td>\n",
       "      <td>4303.805005</td>\n",
       "      <td>12573.280748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health</td>\n",
       "      <td>49</td>\n",
       "      <td>25639</td>\n",
       "      <td>45190</td>\n",
       "      <td>21128</td>\n",
       "      <td>6236.866290</td>\n",
       "      <td>12090.551444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antivax</td>\n",
       "      <td>104</td>\n",
       "      <td>14009</td>\n",
       "      <td>26321</td>\n",
       "      <td>11312</td>\n",
       "      <td>1457.591635</td>\n",
       "      <td>3521.396328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>French</td>\n",
       "      <td>57</td>\n",
       "      <td>10449</td>\n",
       "      <td>27244</td>\n",
       "      <td>9056</td>\n",
       "      <td>3291.912570</td>\n",
       "      <td>11467.405191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Indian</td>\n",
       "      <td>85</td>\n",
       "      <td>7260</td>\n",
       "      <td>20858</td>\n",
       "      <td>6327</td>\n",
       "      <td>12996.462042</td>\n",
       "      <td>49057.459902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FreedomUK</td>\n",
       "      <td>80</td>\n",
       "      <td>3616</td>\n",
       "      <td>10626</td>\n",
       "      <td>3280</td>\n",
       "      <td>2657.267008</td>\n",
       "      <td>15368.555077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Community_Name  Community_Id  Prior_Active_Users  Posterior_Active_Users  \\\n",
       "0           Dems            13               51319                   87173   \n",
       "1           Reps            48               33878                   68566   \n",
       "2    Disenfranch             6               22596                   57201   \n",
       "3         Health            49               25639                   45190   \n",
       "4        Antivax           104               14009                   26321   \n",
       "5         French            57               10449                   27244   \n",
       "6         Indian            85                7260                   20858   \n",
       "7      FreedomUK            80                3616                   10626   \n",
       "\n",
       "   Continuous_Active_Users    Prior_Mean  Posterior_Mean  \n",
       "0                    46700   8118.406542    25295.379267  \n",
       "1                    32197   3321.962841    15161.272587  \n",
       "2                    19770   4303.805005    12573.280748  \n",
       "3                    21128   6236.866290    12090.551444  \n",
       "4                    11312   1457.591635     3521.396328  \n",
       "5                     9056   3291.912570    11467.405191  \n",
       "6                     6327  12996.462042    49057.459902  \n",
       "7                     3280   2657.267008    15368.555077  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "data = pandas.read_csv('prepost_followers.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\"Community Name\": \"bla\", \"Community Id\": \"Community_Id\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Followers Correlation with Community\n",
    "\n",
    "For each node:\n",
    "\n",
    "- X = [mean posterior (followers + friends),mean prior (followers + friends)]\n",
    "- Y = [posterior tweet count,prior tweet count]\n",
    "- Z = its community\n",
    "- ID = Id\n",
    "- Other statistics\n",
    "\n",
    "Is there a correlation between X and Y?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_data:\n",
    "    PT = nx.read_gexf('PT-pruned.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_data(auth):\n",
    "    data = popularity_dict[auth]\n",
    "    date_break = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "    prior = np.array([0,0]).astype('int64')\n",
    "    posterior = np.array([0,0]).astype('int64')\n",
    "    for entry in data:\n",
    "        date = datetime.datetime.strptime(entry[0],'%y-%m-%d-%H:%M:%S')\n",
    "        if date <= date_break:\n",
    "            prior[0] += entry[1] + entry[2] # count followers and friends\n",
    "            prior[1] += 1\n",
    "        if date_break <= date:\n",
    "            posterior[0] += entry[1] + entry[2] # count followers and friends\n",
    "            posterior[1] += 1\n",
    "    prior_mean = prior[0]/prior[1]\n",
    "    posterior_mean = posterior[0]/posterior[1]\n",
    "    \n",
    "    ID = auth\n",
    "    C = get_node_com(auth)\n",
    "    X_1 = prior_mean\n",
    "    X_2 = posterior_mean\n",
    "    Y_1 = prior[1]\n",
    "    Y_2 = posterior[1]\n",
    "    R = PT.nodes[auth]['total_retweets']\n",
    "    F = PT.nodes[auth]['neighbors']\n",
    "    I = PT.nodes[auth]['w_indegree']\n",
    "    \n",
    "    return np.array([ID,C,X_1,X_2,Y_1,Y_2,R,F,I])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_data:\n",
    "    # Try it out\n",
    "    for author in popularity_dict:\n",
    "        if check_auth_continuity(author):\n",
    "            winner = author\n",
    "            break   \n",
    "    get_author_data(winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_data:\n",
    "    results = pd.DataFrame(columns =['Id','Community', 'Prior_Mean_Followers', 'Posterior_Mean_Followers', \\\n",
    "                                     'Prior_Tweet_Count', 'Posterior_Tweet_Count','Retweets',\\\n",
    "                                     'Neighbors','In_Degree'])\n",
    "    \n",
    "    for author in tqdm(popularity_dict):\n",
    "        if check_auth_continuity(author):\n",
    "            data = get_author_data(author)\n",
    "            results.loc[len(results)] = data\n",
    "\n",
    "    results.to_csv(\"user_features\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the data\n",
    "data = pd.read_csv(\"user_features\")\n",
    "X = data['Prior_Tweet_Count']-data['Posterior_Tweet_Count']\n",
    "Y = data['Prior_Mean_Followers']-data['Posterior_Mean_Followers']\n",
    "Z = data['Community']\n",
    "\n",
    "# Try it out\n",
    "pearsons1 = True        \n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
    "if pearsons1:\n",
    "    corr1 = scipy.stats.pearsonr(X,Y)\n",
    "    print(corr1)\n",
    "    corr2 = scipy.stats.pearsonr(Z,Y)\n",
    "    print(corr2)\n",
    "\n",
    "# Pandas is the best\n",
    "pearsons2 = True\n",
    "\n",
    "if pearsons2:\n",
    "    # Pandas data frame from X and Y\n",
    "    XY1 = pd.DataFrame(list(zip(X, Y)), \n",
    "                   columns =['Delta_Twit_Count', 'Delta_Mean'])\n",
    "    print(XY1.corr(method='pearson', min_periods=1))\n",
    "    XY2 = pd.DataFrame(list(zip(Z, Y)), \n",
    "                   columns =['Community', 'Delta_Mean'])\n",
    "    print(XY2.corr(method='pearson', min_periods=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Community Aggregate Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [13,48,6,49,104,57,85,80]\n",
    "labels = [\"Democrats\",\"Republicans\",\"Unorthodox\",\"Public Health\",\"Anti-Vaxxers\",\"French\",\"Indian\",\"FreedomUK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_com(node):\n",
    "    com = com_data[com_data['Id']==node]['modularity_class']\n",
    "    val = com.values[0]\n",
    "    return val\n",
    "\n",
    "def check_auth_continuity(author):\n",
    "    date_break = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "    data = popularity_dict[author]\n",
    "    pre = False\n",
    "    post = False\n",
    "    for entry in data:\n",
    "        date = datetime.datetime.strptime(entry[0],'%y-%m-%d-%H:%M:%S')\n",
    "        if date <= date_break:\n",
    "            pre=True\n",
    "        if date_break <= date:\n",
    "            post=True\n",
    "    if (pre & post):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = ['GreatTammie','CjPolka','RMindedPatriots']\n",
    "for node in nodes:\n",
    "    print(data[data['Id']==node]['Retweets'])\n",
    "type(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"user_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Id']=='CjPolka']['In_Degree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_nodes = get_com_nodes(clusters[7])\n",
    "    \n",
    "Retweets = float(0)\n",
    "Retweeted = float(0)\n",
    "for node in tqdm(com_nodes):\n",
    "    Retweets += data[data['Id']==node]['Retweets']\n",
    "    Retweeted += data[data['Id']==node]['In_Degree']\n",
    "\n",
    "Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in tqdm(com_nodes):\n",
    "    print(data[data['Id']==node]['Retweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recompute:\n",
    "    PT = nx.read_gexf('PT-pruned.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT.nodes['Dr_Ivanoncologo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recompute:\n",
    "    results = pd.DataFrame(columns=['Community_Name','Community_Id','Retweets','Retweeted'])\n",
    "\n",
    "    for i in tqdm(range(len(clusters))):\n",
    "        row = []\n",
    "        row.append(labels[i])\n",
    "        row.append(clusters[i])\n",
    "        com_nodes = get_com_nodes(clusters[i])\n",
    "        Retweets = int(0)\n",
    "        Retweeted = int(0)\n",
    "        for node in tqdm(com_nodes):\n",
    "            Retweets += PT.nodes[node]['total_retweets']\n",
    "            Retweeted += PT.nodes[node]['w_indegree']\n",
    "        row.append(int(Retweets))\n",
    "        row.append(int(Retweeted))\n",
    "        # Beautiful trick\n",
    "        results.loc[len(results)] = row\n",
    "\n",
    "        results.to_csv('tweet_flow.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('prepost_followers.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [data,results]\n",
    "total = pd.concat(frames, keys='Community_Id', axis = 1)\n",
    "total.to_csv('community_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Community_Name','Community_Id','Retweets','Retweeted'])\n",
    "\n",
    "for i in tqdm(range(len(clusters))):\n",
    "    row = []\n",
    "    row.append(labels[i])\n",
    "    row.append(clusters[i])\n",
    "    com_nodes = get_com_nodes(clusters[i])\n",
    "    Retweets = int(0)\n",
    "    Retweeted = int(0)\n",
    "    for node in tqdm(com_nodes):\n",
    "        Retweets += PT.nodes[node]['total_retweets']\n",
    "        Retweeted += PT.nodes[node]['w_indegree']\n",
    "    row.append(int(Retweets))\n",
    "    row.append(int(Retweeted))\n",
    "    # Beautiful trick\n",
    "    results.loc[len(results)] = row\n",
    "    \n",
    "    results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('Com_ret_ret.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "or node in com_nodes:\n",
    "    Retweets += data[data['Id']==node]['Retweets']\n",
    "    Retweeted += data[data['Id']==node]['In_Degree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = False\n",
    "\n",
    "if recompute:\n",
    "    results = pd.DataFrame(columns=['Community_Name','Community_Id','Prior_Active_Users','Posterior_Active_Users',\\\n",
    "                                    'Continuous_Active_Users','Prior_Mean','Posterior_Mean'])\n",
    "    for i in tqdm(range(len(clusters))):\n",
    "        data = []\n",
    "        data.append(labels[i])\n",
    "        data.append(clusters[i])\n",
    "        com_nodes = get_com_nodes(clusters[i])\n",
    "        prior_count = 0\n",
    "        posterior_count = 0\n",
    "        continuity_count = 0\n",
    "        for node in com_nodes:\n",
    "            if check_auth_time(node,pre=True):\n",
    "                prior_count += 1\n",
    "            if check_auth_time(node,pre=False):\n",
    "                posterior_count += 1\n",
    "            if check_auth_continuity(node):\n",
    "                continuity_count += 1\n",
    "        data.append(prior_count)\n",
    "        data.append(posterior_count)\n",
    "        data.append(continuity_count)\n",
    "        prior_mean = get_mean_followers(clusters[i],pre=True)\n",
    "        data.append(prior_mean)\n",
    "        posterior_mean = get_mean_followers(clusters[i],pre=False)\n",
    "        data.append(posterior_mean)\n",
    "        results.loc[len(results)] = data\n",
    "    results.to_csv('prepost_followers.csv', index=False)\n",
    "    results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = pd.DataFrame(columns =['Id','Community', 'Prior_Mean_Followers', 'Posterior_Mean_Followers', \\\n",
    "                                 'Prior_Tweet_Count', 'Posterior_Tweet_Count','Retweets',\\\n",
    "                                 'Neighbors','In_Degree'])\n",
    "\n",
    "results2 = pd.DataFrame(columns=['Community_Name','Community_Id','Prior_Active_Users','Posterior_Active_Users',\\\n",
    "                                    'Continuous_Active_Users','Prior_Mean','Posterior_Mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_com_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_com_data:\n",
    "    results2 = pd.DataFrame(columns=['Community_Name','Community_Id','Prior_Active_Users','Posterior_Active_Users',\\\n",
    "                                    'Continuous_Active_Users','Prior_Mean','Posterior_Mean','Retweets','Retweeted'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv(\"user_features_original_working\")\n",
    "\n",
    "feature_cols = ['Delta_Twit_Count','Community']\n",
    "X = data[feature_cols]\n",
    "y = data.Delta_Mean\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "\n",
    "type(X_train.iloc[(0,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "\n",
    "linear.fit(X_train,y_train)\n",
    "y_linear_pred=linear.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_linear_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "# Coefficients\n",
    "print(linear.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "y_logreg_pred=logreg.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_logreg_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "# Coefficients\n",
    "print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict = pd.read_csv(\"PT-pruned-louvain.gexf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict.drop(columns=['Label', '0','1'])\n",
    "main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"user_features\")\n",
    "#data.drop(columns=['Unnamed: 0'])\n",
    "data.merge(main_dict, on = 'Id')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(zip(X, Y,Z)), \n",
    "               columns =['Delta_Mean', 'Delta_Twit_Count', 'Delta_Twit_Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of strings \n",
    "lst = ['Geeks', 'For', 'Geeks', 'is', 'portal', 'for', 'Geeks'] \n",
    "  \n",
    "# list of int \n",
    "lst2 = [11, 22, 33, 44, 55, 66, 77] \n",
    "  \n",
    "# Calling DataFrame constructor after zipping \n",
    "# both lists, with columns specified \n",
    "df = pd.DataFrame(list(zip(lst, lst2)), \n",
    "               columns =['Name', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy['Delta_Mean'] = copy.apply(lambda x: get_author_XYZ(copy.['Id'][x], axis=1)\n",
    "copy['Delta_Twit_Count'] = copy.apply(lambda x: get_author_XYZ(x['Id'][1], axis=1)\n",
    "#copy['Delta_Twit_Count'] = copy.apply(lambda x: my_function(x['Id'][0], axis=1)\n",
    "get_author_XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is the best\n",
    "# Pandas data frame from X and Y\n",
    "XY = pd.DataFrame(list(zip(X, Y)), \n",
    "               columns =['Delta_Mean', 'Delta_Twit_Count'])\n",
    "XY.corr(method='pearson', min_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data to main Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add this data to the main dictionary, because it is useful\n",
    "com = com_data[com_data['Id']=='johnjosephTX']['modularity_class']\n",
    "val = com.values[0]\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = pd.read_csv(\"PT-pruned-louvain.gexf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in copy['Id']:\n",
    "    print(type(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(get_author_XYZ(copy['Id'][2])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in copy['Id']:\n",
    "    print(get_author_XYZ(copy['Id'][author])[0])\n",
    "    #copy['Delta_Mean'] = get_author_XYZ(copy['Id'][author])[0]\n",
    "\n",
    "copy\n",
    "#copy['Delta_Mean'] = copy.apply(lambda x: get_author_XYZ(copy['Id'][x])[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy['Delta_Mean'] = copy.apply(lambda x: get_author_XYZ(copy.['Id'][x], axis=1)\n",
    "copy['Delta_Twit_Count'] = copy.apply(lambda x: get_author_XYZ(x['Id'][1], axis=1)\n",
    "#copy['Delta_Twit_Count'] = copy.apply(lambda x: my_function(x['Id'][0], axis=1)\n",
    "get_author_XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['Symbol'].apply(getquotetoday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_column_name'] = df.apply(lambda x: my_function(x['value_1'], x['value_2']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for author in tqdm(popularity_dict):\n",
    "    if check_auth_continuity(author):\n",
    "        data = get_author_XY(author)\n",
    "        X.append(data[0])\n",
    "        Y.append(data[1])\n",
    "        \n",
    "corr = scipy.stats.pearsonr(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is the best\n",
    "corr(method='pearson', min_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time2 = elapsed_time2 - elapsed_time\n",
    "print(elapsed_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time2 = elapsed_time2 - elapsed_time\n",
    "print(elapsed_time2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
