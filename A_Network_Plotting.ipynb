{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "\n",
    "import pprint\n",
    "import glob\n",
    "from random import random, randrange\n",
    "from random import choice\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "import subprocess\n",
    "import shlex\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from collections import Counter\n",
    "from scipy.signal import savgol_filter\n",
    "import itertools\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation,NMF\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network\n",
    "PT = nx.read_gexf('PT-pruned.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [13,48,6,49,104]#,57,85,80]\n",
    "cluster_names = ['Democrats',\"Maga\",\"Socialists\",\"Health\",\"Antivaxers\",\"French\",\"Indian\",\"FreedomUK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete outside nodes\n",
    "H = PT.copy()\n",
    "print(len(H.nodes()))\n",
    "exclude = []\n",
    "for node in H.nodes:\n",
    "    if H.nodes[node]['louvain'] not in clusters:\n",
    "        exclude.append(node)\n",
    "        \n",
    "H.remove_nodes_from(exclude)\n",
    "print(len(H.nodes())/len(PT.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_degree is roughly the amount of people that retweeted them\n",
    "out_degree = 4\n",
    "exclude = []\n",
    "for node in H.nodes:\n",
    "    if H.out_degree(node)<out_degree:\n",
    "        exclude.append(node)\n",
    "            \n",
    "H.remove_nodes_from(exclude)\n",
    "print(len(H.nodes())/len(PT.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge weight is the amount of times one [person retweeted the other]\n",
    "edge_weight = 0\n",
    "exclude = []\n",
    "for edge in H.edges():\n",
    "    if H.edges[edge]['weight'] < edge_weight:\n",
    "        exclude.append(edge)\n",
    "\n",
    "H.remove_edges_from(exclude)\n",
    "print(len(H.nodes())/len(PT.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.remove_nodes_from(list(nx.isolates(H)))\n",
    "print(len(H.nodes())/len(PT.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same amoung per community\n",
    "equal_pops = False\n",
    "if equal_pops:\n",
    "    cluster_size=[]\n",
    "    for cluster in clusters:\n",
    "        count = 0\n",
    "        for node in H.nodes():\n",
    "            if H.nodes[node]['louvain'] == cluster:\n",
    "                count += 1\n",
    "        cluster_size.append(count)\n",
    "    cut = min(cluster_size)\n",
    "\n",
    "    def get_bottom(cluster,n):\n",
    "        ranking = dict()\n",
    "        for node in H.nodes():\n",
    "            if H.nodes[node]['louvain'] == cluster:\n",
    "                ranking[node]=H.nodes[node]['neighbors']\n",
    "        sort_nodes = sorted(ranking.items(), key=lambda x: x[1], reverse=True)\n",
    "        sort_nodes = sort_nodes[n:]\n",
    "        result =[i[0] for i in sort_nodes]\n",
    "        return result\n",
    "\n",
    "    exclude = []\n",
    "    for cluster in clusters:\n",
    "        ex = get_bottom(cluster,cut)\n",
    "        exclude.extend(ex)\n",
    "\n",
    "    #print(exclude)\n",
    "    H.remove_nodes_from(exclude)\n",
    "    print(len(H.nodes())/len(PT.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = True\n",
    "if pc:\n",
    "    giant = max(nx.algorithms.components.weakly_connected_components(H), key=len)\n",
    "    tocutnodes = []\n",
    "    for node in H.nodes():\n",
    "        if node not in giant:\n",
    "            tocutnodes.append(node)\n",
    "    H.remove_nodes_from(tocutnodes)\n",
    "    print(len(H.nodes())/len(PT.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(H,'PT-pruned-plotting.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
