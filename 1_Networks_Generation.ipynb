{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full and Sliced Network Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from itertools import combinations\n",
    "import pprint\n",
    "import json\n",
    "import glob\n",
    "from random import random, randrange\n",
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import numpy\n",
    "import time\n",
    "import functools\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "f = open('pruned_retweet_dict','rb')\n",
    "retweet_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "#get the set of authors who were actually retweeted, \n",
    "# as this becomes useful in later steps. \n",
    "\n",
    "rt_author_set = set()\n",
    "for a in retweet_dict:\n",
    "    rt_author_set.add(retweet_dict[a]['author'])\n",
    "\n",
    "#i believe checking frozensets is quicker\n",
    "rt_author_set=frozenset(rt_author_set)\n",
    "print(len(rt_author_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Full Time Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directed Graph: \n",
    "# A -> B if B retweeted A. \n",
    "# Edges are weighted with retweet count\n",
    "# nodes have a count with the total amount of tweets they generated\n",
    "def build_PT_network(retweet_dict,rt_author_set,add_metadata = False):\n",
    "    G = nx.DiGraph()\n",
    "    for a in rt_author_set:\n",
    "        G.add_node(a,count=0)\n",
    "    for i in tqdm(retweet_dict):\n",
    "        a = retweet_dict[i]['author']\n",
    "        G.nodes[a]['count']+=1\n",
    "\n",
    "    for i in tqdm(retweet_dict):\n",
    "        rlist = retweet_dict[i]['rt_list']\n",
    "        rauthor = retweet_dict[i]['author']\n",
    "        for a,b in rlist:\n",
    "            if rauthor != a: #no self-loops\n",
    "                if (a in rt_author_set) and (rauthor in rt_author_set):\n",
    "                    if G.has_edge(rauthor,a):\n",
    "                        G.edges[rauthor,a]['weight'] += 1\n",
    "                        # Now to make sure we use the earliest time tag\n",
    "                        if add_metadata:\n",
    "                            stored_date = G.edges[rauthor,a]['date']\n",
    "                            stored_date = datetime.strptime(stored_date,'%y-%m-%d-%H:%I:%M')\n",
    "                            new_date = datetime.strptime(b,'%y-%m-%d-%H:%I:%M')\n",
    "                            if new_date < stored_date:\n",
    "                                G.edges[rauthor,a][\"date\"]= b\n",
    "                    else:\n",
    "                        G.add_edge(rauthor,a,weight=1)\n",
    "                        if add_metadata:\n",
    "                            G.edges[rauthor,a][\"date\"]= b\n",
    " \n",
    "    \n",
    "    return G \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_network(G,minimum_edgeweight=0,minumum_count=0,component=True,isolated=False):\n",
    "    # Remove low weight edges\n",
    "    tocut = []                 \n",
    "    if minimum_edgeweight > 0:\n",
    "        for a,b,w in G.edges(data='weight'):\n",
    "            if w <= minimum_edgeweight:\n",
    "                tocut.append((a,b))\n",
    "    G.remove_edges_from(tocut)\n",
    "    \n",
    "    # Remove low count nodes\n",
    "    tocutnodes = []\n",
    "    if minumum_count > 0:\n",
    "        for node in G.nodes():\n",
    "            if G.nodes[node]['count'] <= minumum_count:\n",
    "                tocutnodes.append(node) \n",
    "        G.remove_nodes_from(tocutnodes)\n",
    "            \n",
    "    # Keep only the principal (weakly connected) component\n",
    "    if component:\n",
    "        giant = max(nx.algorithms.components.weakly_connected_components(G), key=len)\n",
    "        tocutnodes = []\n",
    "        for node in G.nodes():\n",
    "            if node not in giant:\n",
    "                tocutnodes.append(node)\n",
    "        G.remove_nodes_from(tocutnodes)\n",
    "    \n",
    "    if isolated:\n",
    "        G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)\n",
    "PT_full = build_PT_network(retweet_dict,rt_author_set,add_metadata=False)\n",
    "print(len(PT_full.nodes()))\n",
    "nx.write_gexf(PT_full,'PT-full.gexf')\n",
    "PT = prune_network(PT_full,minimum_edgeweight=0,minumum_count=0,component=True,isolated=False)\n",
    "nx.write_gexf(PT,'PT-pruned.gexf')\n",
    "print(len(PT.nodes()))\n",
    "elapsed_time2 = time.time() - start_time\n",
    "elapsed_time2 = elapsed_time2 - elapsed_time\n",
    "print(elapsed_time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliced Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_PT_network(date1,date2,retweet_dict):\n",
    "    G = nx.DiGraph()\n",
    "    date1 = datetime.strptime(date1,\"%d/%m/%y\")\n",
    "    date2 = datetime.strptime(date2,\"%d/%m/%y\")\n",
    "    \n",
    "    for a in PT.nodes():\n",
    "        G.add_node(a,count=0)\n",
    "\n",
    "    for i in tqdm(retweet_dict):\n",
    "        rlist = retweet_dict[i]['rt_list']\n",
    "        rauthor = retweet_dict[i]['author']\n",
    "        \n",
    "        t_date = datetime.strptime(retweet_dict[i]['date'],'%y-%m-%d-%H:%M:%S')\n",
    "        if (date1 < t_date) and (t_date <= date2):\n",
    "            if rauthor in PT.nodes():\n",
    "                G.nodes[rauthor]['count']+=1\n",
    "        \n",
    "        for a,b in rlist:\n",
    "            rt_date = datetime.strptime(b,'%y-%m-%d-%H:%M:%S')\n",
    "            if (date1 < rt_date) and (rt_date <= date2):\n",
    "                if rauthor != a: #no self-loops\n",
    "                    if (a in PT.nodes()) and (rauthor in PT.nodes()):\n",
    "                        # There is no time frame consideration here\n",
    "                        if G.has_edge(rauthor,a):\n",
    "                            G.edges[rauthor,a]['weight'] += 1                          \n",
    "                        else:\n",
    "                            G.add_edge(rauthor,a,weight=1)\n",
    "                            \n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to keep nodes without edges because they correspond to \n",
    "# the original network - so we do not prune the slices\n",
    "# I use slightly larger intervals to the past and future cause caution\n",
    "PT1 = build_PT_network('24/12/19','11/03/20',retweet_dict)\n",
    "nx.write_gexf(PT1,'PT-Slice1.gexf')\n",
    "print(\"PT1 is done\")\n",
    "PT2 = build_PT_network('11/03/20','29/05/20',retweet_dict)\n",
    "nx.write_gexf(PT2,'PT-Slice2.gexf')\n",
    "print(\"PT2 is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the lists are the same   \n",
    "def comparelists(l1,l2):\n",
    "    if functools.reduce(lambda x, y : x and y, map(lambda p, q: p == q,l1,l2), True): \n",
    "        print (\"The lists are the same\") \n",
    "    else: \n",
    "        print (\"The lists are not the same\")\n",
    "        \n",
    "comparelists(PT.nodes(),PT1.nodes())\n",
    "comparelists(PT.nodes(),PT2.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add node features to networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"PT-pruned-louvain.gexf.csv\")\n",
    "\n",
    "# First we incorporate the Gephi modularity\n",
    "for index, row in data.iterrows():\n",
    "    author = row['Id']\n",
    "    community = row[\"modularity_class\"]\n",
    "    PT.nodes[author]['louvain']=community\n",
    "    PT1.nodes[author]['louvain']=community\n",
    "    PT2.nodes[author]['louvain']=community\n",
    "\n",
    "nx.write_gexf(PT,'PT-pruned.gexf')\n",
    "nx.write_gexf(PT1,'PT-Slice1.gexf')\n",
    "nx.write_gexf(PT2,'PT-Slice2.gexf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
