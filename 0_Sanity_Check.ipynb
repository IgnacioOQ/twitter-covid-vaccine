{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a basic sanity check for our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u1085188\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "\n",
    "import pprint\n",
    "import json\n",
    "import glob\n",
    "from random import random, randrange\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "import subprocess\n",
    "import shlex\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from scipy.signal import savgol_filter\n",
    "import itertools\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 17.064847946166992\n"
     ]
    }
   ],
   "source": [
    "# Using the regular dictionary\n",
    "f = open('retweet_dict_and_counts','rb')\n",
    "retweet_dict = pickle.load(f)\n",
    "f.close()\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: \" + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Check: Time Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1271451/1271451 [02:29<00:00, 8508.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retweets before: 3413021\n",
      "Retweets after: 14501140\n",
      "Total retweets: 17914161\n",
      "Total increase: 424.87696383936697\n",
      "The latest retweet on record is: 2020-05-26 23:11:59\n",
      "The earliest retweet on record is: 2020-01-01 00:12:00\n",
      "Elapsed time: 166.51526999473572\n",
      "Window for retweets is correct.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Count retweets before and after the declaration of pandemic\n",
    "cutoff = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "before = 0\n",
    "after = 0\n",
    "latest_retweet = cutoff\n",
    "earliest_retweet = cutoff\n",
    "for tweet in tqdm(retweet_dict):\n",
    "    for a,d in retweet_dict[tweet]['rt_list']:\n",
    "        rt_date = datetime.datetime.strptime(d,'%y-%m-%d-%H:%M:%S')\n",
    "        if (rt_date < cutoff):\n",
    "            before += 1\n",
    "        elif (cutoff < rt_date):\n",
    "            after += 1\n",
    "        if (latest_retweet < rt_date):\n",
    "            latest_retweet = rt_date\n",
    "        if (earliest_retweet > rt_date):\n",
    "            earliest_retweet = rt_date\n",
    "        \n",
    "print(\"Retweets before:\",before)\n",
    "print(\"Retweets after:\",after)\n",
    "print(\"Total retweets:\",before+after)\n",
    "print('Total increase:', after*100/before)\n",
    "print(\"The latest retweet on record is:\", latest_retweet)\n",
    "print(\"The earliest retweet on record is:\", earliest_retweet)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: \" + str(elapsed_time))\n",
    "\n",
    "print(\"Window for retweets is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1271451/1271451 [00:11<00:00, 111849.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets before: 249140\n",
      "Tweets after: 1022311\n",
      "Total tweets: 1271451\n",
      "Total increase: 410.3359556875652\n",
      "The latest tweet on record is: 2020-05-22 00:12:00\n",
      "The earliest tweet on record is: 2019-12-27 00:12:02\n",
      "Elapsed time: 177.8896987438202\n",
      "Window for tweets is correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Count tweets before and after the declaration of pandemic\n",
    "cutoff = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "before = 0\n",
    "after = 0\n",
    "latest_tweet = cutoff\n",
    "earliest_tweet = cutoff\n",
    "for tweet in tqdm(retweet_dict):\n",
    "    t_date = datetime.datetime.strptime(retweet_dict[tweet]['date'],'%y-%m-%d-%H:%M:%S')\n",
    "    if (t_date < cutoff):\n",
    "        before += 1\n",
    "    elif (cutoff < t_date):\n",
    "        after += 1\n",
    "    if (latest_tweet < t_date):\n",
    "        latest_tweet = t_date\n",
    "    if (earliest_tweet > t_date):\n",
    "        earliest_tweet = t_date\n",
    "\n",
    "print(\"Tweets before:\",before)\n",
    "print(\"Tweets after:\",after)\n",
    "print(\"Total tweets:\",before+after)\n",
    "print('Total increase:', after*100/before)\n",
    "print(\"The latest tweet on record is:\", latest_tweet)\n",
    "print(\"The earliest tweet on record is:\", earliest_tweet)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: \" + str(elapsed_time))\n",
    "\n",
    "print(\"Window for tweets is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of authors is: 534403\n"
     ]
    }
   ],
   "source": [
    "rt_author_set = set()\n",
    "for a in retweet_dict:\n",
    "    rt_author_set.add(retweet_dict[a]['author'])\n",
    "    \n",
    "print('Total amount of authors is:',len(rt_author_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Check: Misspelling\n",
    "\n",
    "mininglist1 = ['vax', 'vaxxed', 'vaccine', 'vaccination', 'vaccinations', \n",
    "'vaxsafety', 'vax saftey', 'vaccineswork', 'vaccines work', 'vaccinesaftey',\n",
    "'vaccine saftey', 'vaccines revealed', 'vaccinesrevealed', \n",
    "'novax', 'no vax', 'no-vax', 'antivax', 'anti-vax', 'anti vax', 'immunisation', \n",
    "'Vaccin', 'Vaccinaties', 'vaccinatiezorg', 'vaccine injury', 'vax injury',\n",
    "'vaccinatieschade']\n",
    "\n",
    "mininglist2 = ['\\#vax', '\\#vaxxed', '\\#vaccine', '\\#vaccination', '\\#vaccinations', '\\#vaxsafety', '\\#vaccineswork', '\\#vaccinesaftey', '\\#vaccinesrevealed', '\\#novax', '\\#antivax', '\\#immunisation', '\\#Vaccin', '\\#Vaccinaties', '\\#vaccinatiezorg', \n",
    "'\\#vaccinatieschade', '\\#nvkp', '\\#rvp', '\\#rijksvaccinatieprogramma', '\\#vaccineinjury', \n",
    "'\\#vaxinjury', '\\#anti-vax']\n",
    "\n",
    "So actually we need to look for: 'saftey', 'vaccinesaftey', and '\\#vaccinesaftey'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_detector(s):\n",
    "    # first some preprocessing\n",
    "    s = s.strip().lower()\n",
    "    s = s.replace('\\n',\" \")\n",
    "    s = [x for x in s if (x.isalnum() or x == \" \" or x==\"#\" or x==\"@\")]\n",
    "    s = \"\".join(s)\n",
    "    s = \" \".join([x for x in s.split() if ((x not in ENGLISH_STOP_WORDS) \n",
    "                                           and (x.find('http') == -1) \n",
    "                                           #and (x[0] != '#')\n",
    "                                           and (x[0] != '@')\n",
    "                                          and (x != 'amp'))])\n",
    "    \n",
    "    # An xi will give index-integer -1 if the sequence does not appear\n",
    "    x1 = s.find('saftey')\n",
    "    x2 = s.find('vaccinesaftey')\n",
    "    x3 = s.find('#vaccinesaftey')\n",
    "    return max(x1,x2,x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1271451/1271451 [00:27<00:00, 45419.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of misspelled tweets: 26\n",
      "Elapsed time: 206.67106747627258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Find misspelled tweets\n",
    "misspelled_tweets = []\n",
    "for t in tqdm(retweet_dict):\n",
    "    x = light_detector(retweet_dict[t]['text'])\n",
    "    if x > -1:\n",
    "        misspelled_tweets.append(t)\n",
    "\n",
    "print(\"Count of misspelled tweets: \" + str(len(misspelled_tweets)))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: \" + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1271425/1271425 [00:30<00:00, 42314.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of misspelled tweets: 0\n",
      "Elapsed time: 294.566365480423\n"
     ]
    }
   ],
   "source": [
    "# Delete misspelled tweets\n",
    "for t in misspelled_tweets:\n",
    "    del retweet_dict[t]\n",
    "\n",
    "# Check things are good\n",
    "# Find misspelled tweets\n",
    "misspelled_tweets = []\n",
    "for t in tqdm(retweet_dict):\n",
    "    x = light_detector(retweet_dict[t]['text'])\n",
    "    if x > -1:\n",
    "        misspelled_tweets.append(t)\n",
    "\n",
    "print(\"Count of misspelled tweets: \" + str(len(misspelled_tweets)))\n",
    "\n",
    "# Save the new dictionary\n",
    "save = True\n",
    "if save:\n",
    "    f = open(\"pruned_retweet_dict\",\"wb\")\n",
    "    pickle.dump(retweet_dict,f)\n",
    "    f.close()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: \" + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last time it took 232 seconds, so not bad at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
