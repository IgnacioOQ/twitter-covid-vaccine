{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "\n",
    "import pprint\n",
    "import json\n",
    "import glob\n",
    "from random import random, randrange\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pandas\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT = nx.read_gexf('PT-pruned.gexf')\n",
    "PT1 = nx.read_gexf('PT-Slice1.gexf')\n",
    "PT2 = nx.read_gexf('PT-Slice2.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the regular dictionary\n",
    "f = open('author_popularity_dictionary','rb')\n",
    "popularity_dict = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [13,48,6,49,104]\n",
    "labels = [\"Democrats\",\"Republicans\",\"Unorthodox\",\"Public Health\",\"Antivaxxers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an out_degree_centrality algorithm implemented, \n",
    "# https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.out_degree_centrality.html#networkx.algorithms.centrality.out_degree_centrality\n",
    "# but it does not take into account edge weight\n",
    "# and edge weight here is important\n",
    "# So we do it ourselves\n",
    "\n",
    "def find_node_w_outdegree(node,network):\n",
    "    out_degree = float(0)\n",
    "    # https://networkx.org/documentation/stable/reference/classes/generated/networkx.DiGraph.neighbors.html\n",
    "    # .neighbors gives you the 'successors', i.e. the PT.neighbots(n*) are all the nodes n* points to.\n",
    "    for neighbor in network.neighbors(node):\n",
    "        out_degree += network.edges[node,neighbor]['weight']\n",
    "    return(out_degree)\n",
    "\n",
    "def find_node_w_indegree(node,network):\n",
    "    in_degree = float(0)\n",
    "    # https://networkx.org/documentation/stable/reference/classes/generated/networkx.DiGraph.neighbors.html\n",
    "    # .neighbors gives you the 'successors', i.e. the PT.neighbots(n*) are all the nodes n* points to.\n",
    "    for neighbor in network.predecessors(node):\n",
    "        in_degree += network.edges[neighbor,node]['weight']\n",
    "    return(in_degree)\n",
    "\n",
    "def count_neighbors(node,network):\n",
    "    neighbors = float(0)\n",
    "    for neighbor in network.neighbors(node):\n",
    "        neighbors += 1\n",
    "    for neighbor in network.predecessors(node):\n",
    "        neighbors += 1\n",
    "    return(neighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT.nodes['JoeBiden']['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT1.nodes['JoeBiden']['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT2.nodes['JoeBiden']['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_data(auth):\n",
    "    data = popularity_dict[auth]\n",
    "    date_break = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "    prior = np.array([0,0]).astype('int64') # prior [followers,tweet count]\n",
    "    posterior = np.array([0,0]).astype('int64') # posterior [followers,tweet count]\n",
    "    for entry in data:\n",
    "        date = datetime.datetime.strptime(entry[0],'%y-%m-%d-%H:%M:%S')\n",
    "        if date <= date_break:\n",
    "            prior[0] += entry[1] + entry[2] # count followers and friends\n",
    "            prior[1] += 1\n",
    "        if date_break <= date:\n",
    "            posterior[0] += entry[1] + entry[2] # count followers and friends\n",
    "            posterior[1] += 1\n",
    "    \n",
    "    # It might be the case that authors appear in only one of the slices, or both:\n",
    "    if prior[1]>0 and posterior[1]>0:\n",
    "        author_type = 'Continuing'\n",
    "    elif prior[1]>0 and not posterior[1]>0:\n",
    "        author_type = 'Prior Only'\n",
    "    elif posterior[1]>0 and not prior[1]>0:\n",
    "        author_type = 'Posterior Only'\n",
    "    \n",
    "    if prior[1]>0:\n",
    "        prior_mean = prior[0]/prior[1]\n",
    "    else:\n",
    "        prior_mean = 0\n",
    "    if posterior[1]>0:\n",
    "        posterior_mean = posterior[0]/posterior[1]\n",
    "    else:\n",
    "        posterior_mean = 0\n",
    "\n",
    "    if prior[1]>0 or posterior[1]>0:\n",
    "        followers_mean = (prior[0]+posterior[0])/(prior[1]+posterior[1])\n",
    "    else:\n",
    "        followers_mean = 0\n",
    "        \n",
    "   \n",
    "    ID = auth\n",
    "    Com = PT.nodes[auth]['louvain']\n",
    "    X = followers_mean\n",
    "    X_1 = prior_mean\n",
    "    X_2 = posterior_mean\n",
    "    C = PT.nodes[auth]['count']\n",
    "    C_1 = PT1.nodes[auth]['count']\n",
    "    C_2 = PT2.nodes[auth]['count']\n",
    "    R = find_node_w_outdegree(auth,PT)\n",
    "    R_1 = find_node_w_outdegree(auth,PT1)\n",
    "    R_2 = find_node_w_outdegree(auth,PT2)\n",
    "    I = find_node_w_indegree(auth,PT)\n",
    "    I_1 = find_node_w_indegree(auth,PT1)\n",
    "    I_2 = find_node_w_indegree(auth,PT2)\n",
    "    N = count_neighbors(auth,PT)\n",
    "    N_1 = count_neighbors(auth,PT1)\n",
    "    N_2 = count_neighbors(auth,PT2)\n",
    "    T = author_type\n",
    "\n",
    "    \n",
    "    return np.array([ID,Com,X,X_1,X_2,C,C_1,C_2,R,R_1,R_2,I,I_1,I_2,N,N_1,N_2,T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out\n",
    "# NOTATION\n",
    "# Retweet/Retweets: the times this author was retweeted\n",
    "# Retweeted: the times this author retweeted someone else\n",
    "\n",
    "results = pd.DataFrame(columns =['Id','Community', 'Mean_Followers','Prior_Mean_Followers', 'Posterior_Mean_Followers', \\\n",
    "        'Tweet_Count','Prior_Tweet_Count', 'Posterior_Tweet_Count',\\\n",
    "        'Retweet_Count','Prior_Retweet_Count','Posterior_Retweet_Count',\\\n",
    "        'Retweeted_Count','Prior_Retweeted_Count','Posterior_Retweeted_Count',\\\n",
    "        'Neighbors','Prior_Neighbors','Posterior_Neighbors','Author_Type'])\n",
    "\n",
    "data = get_author_data('JoeBiden')\n",
    "results.loc[len(results)] = data\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTATION\n",
    "# Retweet/Retweets: the times this author was retweeted\n",
    "# Retweeted: the times this author retweeted someone else\n",
    "if generate_data:\n",
    "    results = pd.DataFrame(columns =['Id','Community', 'Mean_Followers','Prior_Mean_Followers', 'Posterior_Mean_Followers', \\\n",
    "        'Tweet_Count','Prior_Tweet_Count', 'Posterior_Tweet_Count',\\\n",
    "        'Retweet_Count','Prior_Retweet_Count','Posterior_Retweet_Count',\\\n",
    "        'Retweeted_Count','Prior_Retweeted_Count','Posterior_Retweeted_Count',\\\n",
    "        'Neighbors','Prior_Neighbors','Posterior_Neighbors','Author_Type'])\n",
    "    \n",
    "    for author in tqdm(popularity_dict):\n",
    "        data = get_author_data(author)\n",
    "        results.loc[len(results)] = data\n",
    "\n",
    "    results.to_csv(\"user_features\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('user_features')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Community Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code to generate this csv is at the bottom of this notebook\n",
    "import pandas\n",
    "data = pandas.read_csv('prepost_followers.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Rate_Users_Increase']=data['Posterior_Active_Users']/data['Prior_Active_Users']\n",
    "data['Rate_Followers_Increase']=data['Posterior_Mean_Followers']/data['Prior_Mean_Followers']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [13,48,6,49,104]\n",
    "labels = [\"Democrats\",\"Republicans\",\"Unorthodox\",\"Public Health\",\"Antivaxxers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recompute:\n",
    "    com_data = pd.read_csv(\"PT-pruned-louvain.gexf.csv\")\n",
    "\n",
    "    # Using the popularity dictionary\n",
    "    f = open('author_popularity_dictionary','rb')\n",
    "    popularity_dict = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_com_nodes(com):\n",
    "    com_nodes = []\n",
    "    subset = com_data[com_data['modularity_class']==com]\n",
    "    for i in tqdm(subset['Id']):\n",
    "        com_nodes.append(i)\n",
    "    return com_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_auth_time(author,pre=True):\n",
    "    date_break = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "    data = popularity_dict[author]\n",
    "    value = False\n",
    "    for entry in data:\n",
    "        date = datetime.datetime.strptime(entry[0],'%y-%m-%d-%H:%M:%S')\n",
    "        if pre:\n",
    "            if date <= date_break:\n",
    "                value=True\n",
    "        else:\n",
    "            if date_break <= date:\n",
    "                value=True\n",
    "    return value\n",
    "\n",
    "def check_auth_continuity(author):\n",
    "    date_break = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "    data = popularity_dict[author]\n",
    "    pre = False\n",
    "    post = False\n",
    "    for entry in data:\n",
    "        date = datetime.datetime.strptime(entry[0],'%y-%m-%d-%H:%M:%S')\n",
    "        if date <= date_break:\n",
    "            pre=True\n",
    "        if date_break <= date:\n",
    "            post=True\n",
    "    if (pre & post):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_followers(com,pre=True):\n",
    "    date_break = datetime.datetime.strptime('11/03/20',\"%d/%m/%y\")\n",
    "    com_nodes = get_com_nodes(com)\n",
    "    # Consider only those who were active before and after  \n",
    "    com_auth = []\n",
    "    for node in com_nodes:\n",
    "        if check_auth_continuity(node):\n",
    "            com_auth.append(node)   \n",
    "    com_norm = len(com_auth)\n",
    "    com_count = float(0)\n",
    "    for author in tqdm(com_auth): # only those active before and after\n",
    "        data = popularity_dict[author]\n",
    "        auth_norm = len(data)\n",
    "        auth_count = float(0)\n",
    "        for entry in data:\n",
    "            date = datetime.datetime.strptime(entry[0],'%y-%m-%d-%H:%M:%S')\n",
    "            if pre:\n",
    "                if date <= date_break:\n",
    "                    auth_count += entry[1] # count followers\n",
    "                    auth_count += entry[2] # count friends\n",
    "            else:\n",
    "                if date_break <= date:\n",
    "                    auth_count += entry[1] # count followers\n",
    "                    auth_count += entry[2] # count friends                    \n",
    "        auth_mean = auth_count/auth_norm\n",
    "        com_count += auth_mean\n",
    "    com_mean = com_count/com_norm\n",
    "    return com_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recompute:\n",
    "    results = pd.DataFrame(columns=['Community_Name','Community_Id','Prior_Active_Users','Posterior_Active_Users',\\\n",
    "                                    'Continuous_Active_Users','Prior_Mean_Followers','Posterior_Mean_Followers',\\\n",
    "                                   'Total_Tweet_Count','Prior_Tweet_Count','Posterior_Tweet_Count', \\\n",
    "                                    'Total_OutDegree','Prior_OutDegree', 'Posterior_OutDegree',\\\n",
    "                                   'Total_InDegree','Prior_InDegree', 'Posterior_InDegree'])\n",
    "    for i in range(len(clusters)):\n",
    "        data = []\n",
    "        data.append(labels[i])\n",
    "        data.append(clusters[i])\n",
    "        com_nodes = get_com_nodes(clusters[i])\n",
    "        prior_count = 0\n",
    "        posterior_count = 0\n",
    "        continuity_count = 0\n",
    "        total_tweets = 0\n",
    "        prior_tweets = 0\n",
    "        posterior_tweets = 0\n",
    "        total_outdegree = 0\n",
    "        prior_outdegree = 0\n",
    "        posterior_outdegree = 0\n",
    "        total_indegree = 0\n",
    "        prior_indegree = 0\n",
    "        posterior_indegree = 0\n",
    "        \n",
    "        for node in tqdm(com_nodes):\n",
    "            if check_auth_time(node,pre=True):\n",
    "                prior_count += 1\n",
    "            if check_auth_time(node,pre=False):\n",
    "                posterior_count += 1\n",
    "            if check_auth_continuity(node):\n",
    "                continuity_count += 1\n",
    "            \n",
    "            total_tweets += PT.nodes[node]['count']\n",
    "            prior_tweets += PT1.nodes[node]['count']\n",
    "            posterior_tweets += PT2.nodes[node]['count']\n",
    "            total_outdegree += find_node_w_outdegree(node,PT)\n",
    "            prior_outdegree += find_node_w_outdegree(node,PT1)\n",
    "            posterior_outdegree += find_node_w_outdegree(node,PT2)\n",
    "            total_indegree += find_node_w_indegree(node,PT)\n",
    "            prior_indegree += find_node_w_indegree(node,PT1)\n",
    "            posterior_indegree += find_node_w_indegree(node,PT2)\n",
    "\n",
    "            \n",
    "        data.append(prior_count)\n",
    "        data.append(posterior_count)\n",
    "        data.append(continuity_count)\n",
    "        prior_mean = get_mean_followers(clusters[i],pre=True)\n",
    "        data.append(prior_mean)\n",
    "        posterior_mean = get_mean_followers(clusters[i],pre=False)\n",
    "        data.append(posterior_mean)\n",
    "        data.append(total_tweets)\n",
    "        data.append(prior_tweets)\n",
    "        data.append(posterior_tweets)\n",
    "        data.append(total_outdegree)\n",
    "        data.append(prior_outdegree)\n",
    "        data.append(posterior_outdegree)\n",
    "        data.append(total_indegree)\n",
    "        data.append(prior_indegree)\n",
    "        data.append(posterior_indegree)\n",
    "        \n",
    "        results.loc[len(results)] = data\n",
    "    results.to_csv('prepost_followers.csv', index=False)\n",
    "    results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recompute:\n",
    "    results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Plots\n",
    "\n",
    " - group bar charts: https://matplotlib.org/3.1.0/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py\n",
    "\n",
    " - pie charts: https://matplotlib.org/3.1.0/gallery/pie_and_polar_charts/pie_features.html#sphx-glr-gallery-pie-and-polar-charts-pie-features-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comnunity_data = pd.read_csv(\"prepost_followers.csv\")\n",
    "comnunity_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(comnunity_data['Prior_Tweet_Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "\n",
    "\n",
    "prior = np.array(comnunity_data['Prior_Active_Users'])\n",
    "posterior = np.array(comnunity_data['Posterior_Active_Users'])\n",
    "\n",
    "ind = np.arange(len(prior))  # the x locations for the groups\n",
    "width = 0.30  # the width of the bars\n",
    "\n",
    "rects1 = ax.bar(ind - width/2, prior, width, label='Before', color='b')\n",
    "rects2 = ax.bar(ind + width/2, posterior, width, label='After',color='r')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Author Count')\n",
    "ax.set_title('Author Count Before and After')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(('Democrats', 'Republicans', 'Unorthodox', 'Public Health', 'Antivaxxers'))\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects, xpos='center'):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar in *rects*, displaying its height.\n",
    "\n",
    "    *xpos* indicates which side to place the text w.r.t. the center of\n",
    "    the bar. It can be one of the following {'center', 'right', 'left'}.\n",
    "    \"\"\"\n",
    "\n",
    "    ha = {'center': 'center', 'right': 'left', 'left': 'right'}\n",
    "    offset = {'center': 0, 'right': 1, 'left': -1}\n",
    "\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(offset[xpos]*3, 3),  # use 3 points offset\n",
    "                    textcoords=\"offset points\",  # in both directions\n",
    "                    ha=ha[xpos], va='bottom')\n",
    "\n",
    "\n",
    "#autolabel(rects1, \"center\")\n",
    "#autolabel(rects2, \"center\")\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "\n",
    "prior = np.array(comnunity_data['Prior_Tweet_Count'])\n",
    "posterior = np.array(comnunity_data['Posterior_Tweet_Count'])\n",
    "\n",
    "ind = np.arange(len(prior))  # the x locations for the groups\n",
    "width = 0.30  # the width of the bars\n",
    "\n",
    "rects1 = ax.bar(ind - width/2, prior, width, label='Before', color='b')\n",
    "rects2 = ax.bar(ind + width/2, posterior, width, label='After',color='r')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Tweet Count')\n",
    "ax.set_title('Tweet Count Before and After')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(('Democrats', 'Republicans', 'Unorthodox', 'Public Health', 'Antivaxxers'))\n",
    "ax.legend()\n",
    "\n",
    "########\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "\n",
    "prior = np.array(comnunity_data['Prior_OutDegree'])\n",
    "posterior = np.array(comnunity_data['Posterior_OutDegree'])\n",
    "\n",
    "ind = np.arange(len(prior))  # the x locations for the groups\n",
    "width = 0.30  # the width of the bars\n",
    "\n",
    "rects1 = ax.bar(ind - width/2, prior, width, label='Before', color='b')\n",
    "rects2 = ax.bar(ind + width/2, posterior, width, label='After',color='r')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Retweeted Count')\n",
    "ax.set_title('Retweeted Count Before and After')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(('Democrats', 'Republicans', 'Unorthodox', 'Public Health', 'Antivaxxers'))\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "###########\n",
    "\n",
    "ax = fig.add_subplot(224)\n",
    "\n",
    "prior = np.array(comnunity_data['Prior_InDegree'])\n",
    "posterior = np.array(comnunity_data['Posterior_InDegree'])\n",
    "\n",
    "ind = np.arange(len(prior))  # the x locations for the groups\n",
    "width = 0.30  # the width of the bars\n",
    "\n",
    "rects1 = ax.bar(ind - width/2, prior, width, label='Before', color='b')\n",
    "rects2 = ax.bar(ind + width/2, posterior, width, label='After',color='r')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Retweeting Count')\n",
    "ax.set_title('Retweeting Count Before and After')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(('Democrats', 'Republicans', 'Unorthodox', 'Public Health', 'Antivaxxers'))\n",
    "ax.legend()\n",
    "\n",
    "########\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
